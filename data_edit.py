import os
import cv2
import torch
import numpy as np
from ultralytics import YOLO
from segment_anything import sam_model_registry, SamPredictor
from pathlib import Path
import random

# ====================
# CONFIG
# ====================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# YOLO model (detection)
YOLO_WEIGHTS = "yolov8l.pt"        # b·∫°n c√≥ th·ªÉ ƒë·ªïi sang model ƒë√£ fine-tune
YOLO_IMGSZ   = 1000                # tƒÉng n·∫øu c·∫ßn b·∫Øt v·∫≠t th·ªÉ nh·ªè (1200-1600)
YOLO_CONF    = 0.05
YOLO_IOU     = 0.4
YOLO_MAXDET  = 1000

# SAM model
SAM_CHECKPOINT = "sam_vit_h_4b8939.pth"
SAM_ARCH = "vit_h"

# Heuristic ∆∞u ti√™n "bi·ªÉn s·ªë"
SUS_RATIO_THRESH = 2.5    # w/h > ng∆∞·ª°ng
SUS_AREA_FRAC    = 0.02   # di·ªán t√≠ch < 2% ·∫£nh => nghi l√† bi·ªÉn s·ªë

# IO
IMAGES_DIR   = "images"           # th∆∞ m·ª•c ·∫£nh input (ngu·ªìn)
LABELS_DIR   = "labels"           # N·∫æU b·∫°n v·∫´n mu·ªën l∆∞u nh√£n r·ªùi nh∆∞ c≈© (tu·ª≥ ch·ªçn)
PREVIEW_DIR  = "labeled_images"   # ·∫£nh c√≥ v·∫Ω box ƒë·ªÉ review (tu·ª≥ ch·ªçn)
CLASSES_FILE = "classes.txt"      # l∆∞u mapping class -> id

# Dataset YOLO ƒë·ªÉ train
DATASET_DIR  = "dataset"          # ƒë√≠ch l∆∞u dataset chu·∫©n YOLO
VAL_RATIO    = 0.2                # t·ªâ l·ªá val
# ====================

# ====================
# INIT MODELS
# ====================
yolo_model = YOLO(YOLO_WEIGHTS).to(DEVICE)

sam = sam_model_registry[SAM_ARCH](checkpoint=SAM_CHECKPOINT).to(DEVICE)
predictor = SamPredictor(sam)

# ====================
# LOAD / SAVE CLASSES
# ====================
label_map = {}
next_id = 0

if os.path.exists(CLASSES_FILE):
    with open(CLASSES_FILE, "r", encoding="utf-8") as f:
        classes = [line.strip() for line in f.readlines() if line.strip() != ""]
        label_map = {name: i for i, name in enumerate(classes)}
        next_id = len(classes)
    print(f"üìÇ Loaded {len(label_map)} classes t·ª´ {CLASSES_FILE}")

# ====================
# UTILS
# ====================
def yolo_txt_line(cls_id, xmin, ymin, xmax, ymax, img_w, img_h):
    # YOLO format (normalized)
    x_center = ((xmin + xmax) / 2) / img_w
    y_center = ((ymin + ymax) / 2) / img_h
    bw = (xmax - xmin) / img_w
    bh = (ymax - ymin) / img_h
    return f"{cls_id} {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}"

def ensure_dirs():
    os.makedirs(LABELS_DIR, exist_ok=True)
    os.makedirs(PREVIEW_DIR, exist_ok=True)

def ensure_dataset_dirs():
    for split in ["train", "val"]:
        os.makedirs(os.path.join(DATASET_DIR, "images", split), exist_ok=True)
        os.makedirs(os.path.join(DATASET_DIR, "labels", split), exist_ok=True)

def add_label_line(cls_name, xmin, ymin, xmax, ymax, label_lines, w, h):
    """ƒê·∫£m b·∫£o class -> id nh·∫•t qu√°n + th√™m d√≤ng nh√£n YOLO normalized."""
    global next_id, label_map
    if cls_name not in label_map:
        label_map[cls_name] = next_id
        next_id += 1
    cls_id = label_map[cls_name]
    label_lines.append(yolo_txt_line(cls_id, xmin, ymin, xmax, ymax, w, h))
    return True

def add_plate_by_roi(img, canvas, label_lines, w, h):
    win = "ADD_LICENSE_PLATE (Enter=nh·∫≠n, c=h·ªßy)"
    roi = cv2.selectROI(win, img, fromCenter=False, showCrosshair=True)
    cv2.destroyWindow(win)

    x, y, bw, bh = map(int, roi)
    if bw == 0 or bh == 0:
        return False

    xmin, ymin, xmax, ymax = x, y, x + bw, y + bh

    # Cho ph√©p ƒë·∫∑t t√™n (Enter = 'license_plate')
    label_name = input("Nh√£n cho ROI (Enter = 'license_plate'): ").strip()
    if label_name == "":
        label_name = "license_plate"

    # Th√™m d√≤ng nh√£n YOLO
    global next_id, label_map
    if label_name not in label_map:
        label_map[label_name] = next_id
        next_id += 1
    cls_id = label_map[label_name]
    label_lines.append(yolo_txt_line(cls_id, xmin, ymin, xmax, ymax, w, h))

    # V·∫Ω v√† hi·ªán l·∫°i ngay
    cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)
    cv2.putText(canvas, label_name, (xmin, max(0, ymin - 6)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
    cv2.imshow("PREVIEW", canvas)
    cv2.waitKey(1)

    return True


# ====================
# CORE
# ====================
def process_image(img_path, split_for_dataset="train", also_save_preview=True, also_save_legacy_labels=False):
    """
    - Annotate nh∆∞ code c≈© (YOLO + SAM refine + nh·∫≠p nh√£n th·ªß c√¥ng cho m·ªói box)
    - Th√™m b∆∞·ªõc: cho ph√©p th√™m nhi·ªÅu bi·ªÉn s·ªë b·∫±ng ROI
    - L∆∞u tr·ª±c ti·∫øp th√†nh dataset YOLO: dataset/images/{split}/, dataset/labels/{split}/
    - (tu·ª≥ ch·ªçn) v·∫´n l∆∞u preview & labels c≈© n·∫øu mu·ªën
    """
    global next_id

    img = cv2.imread(img_path)
    if img is None:
        print(f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {img_path}")
        return

    h, w = img.shape[:2]

    # --- YOLO predict ---
    results = yolo_model.predict(
        img,
        conf=YOLO_CONF,
        iou=YOLO_IOU,
        imgsz=YOLO_IMGSZ,
        max_det=YOLO_MAXDET,
        verbose=False
    )[0]

    predictor.set_image(img)

    # L·∫•y boxes + thu·ªôc t√≠nh
    if results.boxes is None or results.boxes.xyxy is None or len(results.boxes.xyxy) == 0:
        print("‚ö†Ô∏è Kh√¥ng c√≥ box t·ª´ YOLO.")
        # v·∫´n cho b·∫°n th√™m bi·ªÉn s·ªë th·ªß c√¥ng n·∫øu mu·ªën
        label_lines = []
        while True:
            choice = input("Kh√¥ng c√≥ box n√†o. Th√™m bi·ªÉn s·ªë th·ªß c√¥ng? (r = ROI, Enter = b·ªè): ").strip().lower()
            if choice == "r":
                added = add_plate_by_roi(img, label_lines, w, h)
                print("‚úÖ ƒê√£ th√™m license_plate." if added else "‚ùå Kh√¥ng th√™m.")
            else:
                break
        if not label_lines:
            return
        # l∆∞u dataset
        ensure_dataset_dirs()
        stem = Path(img_path).stem
        out_img = os.path.join(DATASET_DIR, "images", split_for_dataset, stem + ".jpg")
        out_lbl = os.path.join(DATASET_DIR, "labels", split_for_dataset, stem + ".txt")
        cv2.imwrite(out_img, img)
        with open(out_lbl, "w", encoding="utf-8") as f:
            f.write("\n".join(label_lines))
        print(f"‚úÖ Saved (no-yolo) {out_img}, {out_lbl}")
        return

    boxes = results.boxes.xyxy.cpu().numpy()                       # (N, 4) xyxy
    confs = results.boxes.conf.cpu().numpy() if results.boxes.conf is not None else None
    clses = results.boxes.cls.cpu().numpy() if results.boxes.cls is not None else None
    names = getattr(results, "names", None)  # dict id->name n·∫øu c√≥

    # --- ∆ØU TI√äN BI·ªÇN S·ªê + S·∫ÆP X·∫æP NH·ªé -> L·ªöN ---
    H, W = h, w
    img_area = W * H
    sus, oth = [], []

    for i, (x1, y1, x2, y2) in enumerate(boxes):
        bw, bh = max(1, x2 - x1), max(1, y2 - y1)
        ratio = bw / bh
        area  = bw * bh
        if ratio > SUS_RATIO_THRESH and area < SUS_AREA_FRAC * img_area:
            sus.append(i)   # nghi l√† bi·ªÉn s·ªë
        else:
            oth.append(i)

    def sort_by_area(idxs):
        if not idxs:
            return []
        areas = ((boxes[idxs, 2] - boxes[idxs, 0]) * (boxes[idxs, 3] - boxes[idxs, 1]))
        return [idx for _, idx in sorted(zip(areas, idxs), key=lambda x: x[0])]

    sus_sorted = sort_by_area(sus)  # bi·ªÉn s·ªë nh·ªè -> l·ªõn
    oth_sorted = sort_by_area(oth)  # c√°c box kh√°c nh·ªè -> l·ªõn
    order = sus_sorted + oth_sorted

    boxes = boxes[order]
    if confs is not None: confs = confs[order]
    if clses is not None: clses = clses[order]

    # --- V√≤ng annotate ---
    label_lines = []
    canvas = img.copy()

    for i, box in enumerate(boxes):
        x1, y1, x2, y2 = [int(v) for v in box]

        # SAM b·∫±ng box prompt (·ªïn ƒë·ªãnh h∆°n point prompt)
        box_prompt = np.array([x1, y1, x2, y2])[None, :]
        try:
            masks, scores, _ = predictor.predict(
                point_coords=None,
                point_labels=None,
                box=box_prompt,
                multimask_output=True
            )
            if masks is None or len(masks) == 0:
                # fallback: d√πng bbox g·ªëc
                xmin, ymin, xmax, ymax = x1, y1, x2, y2
            else:
                mask = masks[np.argmax(scores)]
                ys, xs = np.where(mask)
                if len(xs) == 0:
                    xmin, ymin, xmax, ymax = x1, y1, x2, y2
                else:
                    xmin, xmax = int(xs.min()), int(xs.max())
                    ymin, ymax = int(ys.min()), int(ys.max())
        except Exception:
            # n·∫øu SAM l·ªói (thi·∫øu VRAM...), d√πng bbox YOLO
            xmin, ymin, xmax, ymax = x1, y1, x2, y2

        # crop review
        xmin_c, ymin_c = max(0, xmin), max(0, ymin)
        xmax_c, ymax_c = min(w-1, xmax), min(h-1, ymax)
        if xmax_c <= xmin_c or ymax_c <= ymin_c:
            continue

        crop = img[ymin_c:ymax_c, xmin_c:xmax_c]
        if crop.size == 0:
            continue

        # G·ª£i √Ω nh√£n m·∫∑c ƒë·ªãnh t·ª´ YOLO (n·∫øu c√≥)
        suggested = None
        conf_txt = ""
        if clses is not None and names is not None:
            try:
                pred_id = int(clses[i])
                suggested = names.get(pred_id, None) if isinstance(names, dict) else None
            except Exception:
                suggested = None
        if confs is not None:
            conf_txt = f" ({confs[i]:.2f})"

        # Hi·ªÉn th·ªã crop v√† h·ªèi ng∆∞·ªùi d√πng
        cv2.imshow("CROP", crop)
        cv2.waitKey(1)
        if suggested:
            prompt = f"‚Üí Nh·∫≠p t√™n/s·ªë cho box n√†y [Enter = '{suggested}'{conf_txt}, q = b·ªè]: "
        else:
            prompt = "‚Üí Nh·∫≠p t√™n/s·ªë cho box n√†y (q = b·ªè qua): "

        user_input = input(prompt).strip()
        cv2.destroyWindow("CROP")

        if user_input.lower() == "q":
            continue
        label_name = suggested if (user_input == "" and suggested is not None) else user_input

        if label_name == "" or label_name is None:
            # n·∫øu v·∫´n r·ªóng, b·ªè qua
            continue

        # √°nh x·∫° label -> id
        if label_name not in label_map:
            label_map[label_name] = next_id
            next_id += 1
        cls_id = label_map[label_name]

        # l∆∞u d√≤ng nh√£n YOLO
        label_lines.append(yolo_txt_line(cls_id, xmin, ymin, xmax, ymax, w, h))

        # v·∫Ω l√™n canvas (preview)
        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
        cv2.putText(canvas, f"{label_name}", (xmin, max(0, ymin - 6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

    # === Th√™m BI·ªÇN S·ªê th·ªß c√¥ng b·∫±ng ROI (c√≥ th·ªÉ th√™m nhi·ªÅu c√°i) ===
    while True:
        choice = input("Th√™m bi·ªÉn s·ªë th·ªß c√¥ng? (r = v·∫Ω ROI, Enter = xong): ").strip().lower()
        if choice == "r":
            added = add_plate_by_roi(img, canvas, label_lines, w, h)
            print("‚úÖ ƒê√£ th√™m license_plate." if added else "‚ùå Kh√¥ng th√™m.")
        else:
            break

    # X√°c nh·∫≠n & L∆ØU DATASET YOLO
    if label_lines:
        # Cho xem preview (kh√¥ng b·∫Øt bu·ªôc)
        if also_save_preview:
            cv2.imshow("REVIEW", canvas)
            cv2.waitKey(1)
            _ = input("Nh·∫•n Enter ƒë·ªÉ l∆∞u‚Ä¶")
            cv2.destroyWindow("REVIEW")

        # L∆∞u **dataset chu·∫©n YOLO**
        ensure_dataset_dirs()
        stem = Path(img_path).stem
        out_img = os.path.join(DATASET_DIR, "images", split_for_dataset, stem + ".jpg")
        out_lbl = os.path.join(DATASET_DIR, "labels", split_for_dataset, stem + ".txt")

        # ·∫£nh g·ªëc d√πng ƒë·ªÉ train (kh√¥ng ph·∫£i ·∫£nh v·∫Ω box)
        cv2.imwrite(out_img, img)
        with open(out_lbl, "w", encoding="utf-8") as f:
            f.write("\n".join(label_lines))
        print(f"‚úÖ Saved YOLO dataset: {out_img}, {out_lbl}")

        # (tu·ª≥ ch·ªçn) v·∫´n l∆∞u ‚Äúlabels/‚Äù v√† ‚Äúlabeled_images/‚Äù ki·ªÉu c≈© ƒë·ªÉ b·∫°n xem
                # (lu√¥n) L∆∞u ·∫£nh preview ƒë·ªÉ xem l·∫°i
        os.makedirs(PREVIEW_DIR, exist_ok=True)
        preview_img = os.path.join(PREVIEW_DIR, stem + ".jpg")
        cv2.imwrite(preview_img, canvas)
        print(f"üñºÔ∏è  Saved preview: {preview_img}")

        # (tu·ª≥ ch·ªçn) v·∫´n l∆∞u nh√£n ‚Äúki·ªÉu c≈©‚Äù v√†o labels/
        if also_save_legacy_labels:
            os.makedirs(LABELS_DIR, exist_ok=True)
            legacy_label = os.path.join(LABELS_DIR, stem + ".txt")
            with open(legacy_label, "w", encoding="utf-8") as f:
                f.write("\n".join(label_lines))
            print(f"‚ÑπÔ∏è  Also saved legacy label: {legacy_label}")


# ====================
# RUN
# ====================
if __name__ == "__main__":
    # Duy·ªát th∆∞ m·ª•c ·∫£nh input
    if not os.path.exists(IMAGES_DIR):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c ·∫£nh: {IMAGES_DIR}")
    else:
        files = [f for f in os.listdir(IMAGES_DIR) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
        files.sort()

        # Chia train/val c·ªë ƒë·ªãnh theo shuffle 1 l·∫ßn (80/20)
        random.seed(42)
        random.shuffle(files)
        split_idx = int(len(files) * (1 - VAL_RATIO))
        train_files = files[:split_idx]
        val_files   = files[split_idx:]
        print(f"üìä S·ªë ·∫£nh: {len(files)} ‚Üí Train: {len(train_files)}, Val: {len(val_files)}")

        # Annotate & l∆∞u th·∫≥ng v√†o dataset/
        for img_file in train_files:
            process_image(os.path.join(IMAGES_DIR, img_file), split_for_dataset="train",
                          also_save_preview=True, also_save_legacy_labels=False)
        for img_file in val_files:
            process_image(os.path.join(IMAGES_DIR, img_file), split_for_dataset="val",
                          also_save_preview=True, also_save_legacy_labels=False)

    # C·∫≠p nh·∫≠t classes.txt cu·ªëi c√πng (gi·ªØ th·ª© t·ª± ID)
    classes_sorted = sorted(label_map.items(), key=lambda x: x[1])
    with open(CLASSES_FILE, "w", encoding="utf-8") as f:
        for name, _ in classes_sorted:
            f.write(name + "\n")
    print(f"üìÑ Updated {CLASSES_FILE} v·ªõi {len(classes_sorted)} classes.")

    # G·ª£i √Ω t·∫°o dataset.yaml (in ra m√†n h√¨nh)
    yaml_path = os.path.abspath(DATASET_DIR)
    print("\nüëâ T·∫°o file dataset.yaml v·ªõi n·ªôi dung (s·ª≠a path cho ƒë√∫ng):")
    print(f"""\
path: {yaml_path}
train: images/train
val: images/val
names:
  0: car
  1: license_plate
""")
